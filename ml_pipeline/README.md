# MaxSold Machine Learning Pipeline

Complete XGBoost regression pipeline for predicting current bid values.

## ğŸ“ Directory Structure

```
ml_pipeline/
â”œâ”€â”€ scripts/              # Main pipeline scripts
â”‚   â”œâ”€â”€ model_pipeline.py           # Full pipeline with all features
â”‚   â”œâ”€â”€ model_pipeline_quick.py     # Quick pipeline (numeric features)
â”‚   â”œâ”€â”€ model_pipeline_fast.py      # Fast pipeline (sampled data)
â”‚   â””â”€â”€ train_model_minimal.py      # Minimal pipeline (fastest)
â”‚
â”œâ”€â”€ utils/                # Utility scripts
â”‚   â”œâ”€â”€ verify_model_setup.py       # Setup verification
â”‚   â””â”€â”€ launch_pipeline.py          # Pipeline launcher
â”‚
â”œâ”€â”€ bash/                 # Shell scripts
â”‚   â”œâ”€â”€ run_model.sh                # Run pipeline
â”‚   â””â”€â”€ run_model_background.sh     # Run in background
â”‚
â””â”€â”€ docs/                 # Documentation
    â”œâ”€â”€ MODEL_PIPELINE_GUIDE.md     # Complete guide
    â”œâ”€â”€ README_MODEL_PIPELINE.md    # Detailed reference
    â””â”€â”€ ML_PIPELINE_README.py       # Quick reference
```

## ğŸš€ Quick Start

### From Repository Root

```bash
# Verify setup
python ml_pipeline/utils/verify_model_setup.py

# Train minimal model (fastest - 30-60 seconds)
python ml_pipeline/scripts/train_model_minimal.py

# Train with visualizations (1-2 minutes)
python ml_pipeline/scripts/model_pipeline_fast.py

# Full dataset training (2-3 minutes)
python ml_pipeline/scripts/model_pipeline_quick.py

# Complete pipeline with all features (5-10 minutes)
python ml_pipeline/scripts/model_pipeline.py
```

### Using Bash Scripts

```bash
# Run from repository root
bash ml_pipeline/bash/run_model.sh

# Or run in background
bash ml_pipeline/bash/run_model_background.sh
tail -f model_pipeline.log  # Monitor progress
```

## ğŸ“Š Pipeline Scripts

### 1. train_model_minimal.py â­ RECOMMENDED
**Fastest execution (30-60 seconds)**
- Samples 30K rows
- 50 estimators
- Saves model + feature importance
- Perfect for quick testing

### 2. model_pipeline_fast.py
**Quick with visualizations (1-2 minutes)**
- Samples 50K rows
- All diagnostic plots
- Metrics summary

### 3. model_pipeline_quick.py
**Full dataset, numeric features (2-3 minutes)**
- Complete 272K dataset
- Production-quality model
- Comprehensive diagnostics

### 4. model_pipeline.py
**Complete pipeline (5-10 minutes)**
- All feature types (numeric, categorical, datetime)
- Best accuracy
- Full preprocessing pipeline

## ğŸ¯ Model Details

- **Model Type**: XGBoost Regression
- **Target Variable**: `current_bid`
- **Excluded Feature**: `bid_count` (as requested)
- **Train/Test Split**: 80/20
- **Metrics**: RMSE, MAE, RÂ², MAPE

## ğŸ“ˆ Outputs

All outputs are saved to `../../data/models/` (relative to scripts):

```
data/models/
â”œâ”€â”€ xgboost_model.pkl              # Trained model
â”œâ”€â”€ feature_names.pkl               # Feature list
â”œâ”€â”€ label_encoders.pkl              # Encoders (full pipeline only)
â””â”€â”€ output/
    â”œâ”€â”€ feature_importance.csv      # Feature rankings
    â”œâ”€â”€ feature_importance.png      # Top 20 features chart
    â”œâ”€â”€ predictions_comparison.png  # Actual vs predicted
    â”œâ”€â”€ residual_analysis.png       # Residual diagnostics
    â”œâ”€â”€ learning_curve.png          # Training progress
    â”œâ”€â”€ error_distribution.png      # Error analysis
    â””â”€â”€ metrics_summary.txt         # Complete metrics
```

## ğŸ“š Documentation

- **[MODEL_PIPELINE_GUIDE.md](docs/MODEL_PIPELINE_GUIDE.md)** - Complete implementation guide
- **[README_MODEL_PIPELINE.md](docs/README_MODEL_PIPELINE.md)** - Detailed reference
- **[ML_PIPELINE_README.py](docs/ML_PIPELINE_README.py)** - Quick reference display

## ğŸ”§ Usage Examples

### Train and Save Model

```bash
cd /workspaces/maxsold
python ml_pipeline/scripts/train_model_minimal.py
```

### Load and Use Model

```python
import joblib
import pandas as pd

# Load trained model
model = joblib.load('data/models/xgboost_model.pkl')
features = joblib.load('data/models/feature_names.pkl')

# Make predictions
new_data = pd.DataFrame(...)  # Your data
predictions = model.predict(new_data[features])
```

### Verify Setup

```bash
python ml_pipeline/utils/verify_model_setup.py
```

## ğŸ›  Requirements

All dependencies in main `requirements.txt`:
- pandas >= 2.0.0
- numpy >= 1.24.0
- xgboost >= 2.0.0
- scikit-learn >= 1.3.0
- matplotlib >= 3.7.0
- seaborn >= 0.12.0
- joblib >= 1.3.0
- pyarrow >= 14.0.0

## ğŸ“ Notes

- All scripts use relative paths from their location
- Scripts expect to be run from repository root or their own directory
- Data files remain in `data/` directory at repository root
- Model outputs saved to `data/models/` and `data/models/output/`

## ğŸ› Troubleshooting

**Issue**: Module not found
```bash
pip install -r requirements.txt
```

**Issue**: Data not found
```bash
kaggle datasets download -d pearcej/maxsold-final-dataset -p data/final_data/ --unzip
```

**Issue**: Script too slow
```bash
python ml_pipeline/scripts/train_model_minimal.py  # Use fastest version
```

---

**Created**: December 28, 2025  
**Last Updated**: January 2, 2026  
**Version**: 2.0 (Reorganized Structure)
