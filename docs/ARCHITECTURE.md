# MaxSold Feature Engineering Architecture

## System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MAXSOLD FEATURE ENGINEERING                      â”‚
â”‚                              PIPELINE ARCHITECTURE                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           KAGGLE (DATA SOURCE)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ pearcej/raw-maxsold-auction                                            â”‚
â”‚  â€¢ pearcej/raw-maxsold-item                                               â”‚
â”‚  â€¢ pearcej/raw-maxsold-item-enriched                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼ (KaggleDataPipeline.download_dataset)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RAW DATA (LOCAL STORAGE)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ./data/raw/                                                              â”‚
â”‚    â”œâ”€â”€ auction/*.parquet                                                  â”‚
â”‚    â”œâ”€â”€ item/*.parquet                                                     â”‚
â”‚    â””â”€â”€ item_enriched/*.parquet                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚
        â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AUCTION     â”‚ â”‚      ITEM       â”‚ â”‚     ITEM ENRICHED            â”‚
â”‚   FEATURE     â”‚ â”‚    FEATURE      â”‚ â”‚      FEATURE                 â”‚
â”‚   ENGINEER    â”‚ â”‚    ENGINEER     â”‚ â”‚      ENGINEER                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ .fit()        â”‚ â”‚ .fit()          â”‚ â”‚ .fit()                       â”‚
â”‚ .transform()  â”‚ â”‚ .transform()    â”‚ â”‚ .transform()                 â”‚
â”‚               â”‚ â”‚ .save_models()  â”‚ â”‚                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Features:     â”‚ â”‚ Features:       â”‚ â”‚ Features:                    â”‚
â”‚ â€¢ Duration    â”‚ â”‚ â€¢ Embeddings    â”‚ â”‚ â€¢ Brands                     â”‚
â”‚ â€¢ Postal code â”‚ â”‚   (64-dim)      â”‚ â”‚ â€¢ Categories                 â”‚
â”‚ â€¢ Pickup time â”‚ â”‚ â€¢ Bid features  â”‚ â”‚ â€¢ Attributes                 â”‚
â”‚ â€¢ Type flags  â”‚ â”‚                 â”‚ â”‚ â€¢ Text quality               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                  â”‚                          â”‚
        â–¼                  â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ENGINEERED DATA (LOCAL STORAGE)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ./data/engineered/                                                       â”‚
â”‚    â”œâ”€â”€ auction/auction_engineered.parquet                                 â”‚
â”‚    â”œâ”€â”€ item/item_engineered.parquet                                       â”‚
â”‚    â””â”€â”€ item_enriched/item_enriched_engineered.parquet                     â”‚
â”‚                                                                           â”‚
â”‚  ./data/models/                                                           â”‚
â”‚    â””â”€â”€ item_features/                                                     â”‚
â”‚        â”œâ”€â”€ combined_tfidf_vectorizer.pkl    (for deployment)             â”‚
â”‚        â”œâ”€â”€ combined_svd_model.pkl           (for deployment)             â”‚
â”‚        â””â”€â”€ embeddings_metadata.pkl                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ (KaggleDataPipeline.upload_dataset)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      KAGGLE (ENGINEERED DATASETS)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ pearcej/engineered-maxsold-auction                                     â”‚
â”‚  â€¢ pearcej/engineered-maxsold-item                                        â”‚
â”‚  â€¢ pearcej/engineered-maxsold-item-enriched                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ (All 3 datasets loaded)
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    DATASET    â”‚
                    â”‚     MERGER    â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ .merge()      â”‚
                    â”‚               â”‚
                    â”‚ Handles:      â”‚
                    â”‚ â€¢ ID mapping  â”‚
                    â”‚ â€¢ Joins       â”‚
                    â”‚ â€¢ Overlaps    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FINAL MERGED DATASET                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ./data/final/maxsold_final_dataset.parquet                              â”‚
â”‚                                                                           â”‚
â”‚  Contains:                                                                â”‚
â”‚  â€¢ All auction features                                                   â”‚
â”‚  â€¢ All item features (including embeddings)                               â”‚
â”‚  â€¢ All enriched item features                                             â”‚
â”‚  â€¢ Joined on auction_id and item_id                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ (KaggleDataPipeline.upload_dataset)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KAGGLE (FINAL DATASET)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ pearcej/maxsold-final-dataset                                          â”‚
â”‚    Ready for ML model training!                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Interaction Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          TRAINING PHASE                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

run_pipeline.py
     â”‚
     â”œâ”€â”€â–º KaggleDataPipeline.download_dataset()
     â”‚         â”‚
     â”‚         â””â”€â”€â–º Downloads 3 raw datasets
     â”‚
     â”œâ”€â”€â–º AuctionFeatureEngineer()
     â”‚         â”‚
     â”‚         â”œâ”€â”€â–º .fit(training_data)      # Learn categories
     â”‚         â””â”€â”€â–º .transform(data)         # Apply transformations
     â”‚
     â”œâ”€â”€â–º ItemFeatureEngineer()
     â”‚         â”‚
     â”‚         â”œâ”€â”€â–º .fit(training_data)      # Learn TF-IDF vocab + SVD
     â”‚         â”œâ”€â”€â–º .transform(data)         # Generate embeddings
     â”‚         â””â”€â”€â–º .save_models(path)       # â˜… Save for deployment
     â”‚
     â”œâ”€â”€â–º ItemEnrichedFeatureEngineer()
     â”‚         â”‚
     â”‚         â”œâ”€â”€â–º .fit(training_data)      # Learn top brands/categories
     â”‚         â””â”€â”€â–º .transform(data)         # Apply transformations
     â”‚
     â”œâ”€â”€â–º KaggleDataPipeline.upload_dataset()  (Ã—3)
     â”‚         â”‚
     â”‚         â””â”€â”€â–º Upload engineered datasets
     â”‚
     â”œâ”€â”€â–º DatasetMerger.merge()
     â”‚         â”‚
     â”‚         â””â”€â”€â–º Combine all datasets
     â”‚
     â””â”€â”€â–º KaggleDataPipeline.upload_dataset()
               â”‚
               â””â”€â”€â–º Upload final dataset


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INFERENCE PHASE                                 â”‚
â”‚                      (Model Deployment / Live ML)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

your_api.py / scoring_service.py
     â”‚
     â”œâ”€â”€â–º Load trained ML model
     â”‚         model = joblib.load('model.pkl')
     â”‚
     â”œâ”€â”€â–º Load feature engineering transformers
     â”‚         auction_eng = AuctionFeatureEngineer()
     â”‚         auction_eng.fit(reference_data)  # Or load saved state
     â”‚         
     â”‚         item_eng = ItemFeatureEngineer()
     â”‚         item_eng.load_models('path/to/models')  # â˜… Load saved models
     â”‚         
     â”‚         enriched_eng = ItemEnrichedFeatureEngineer()
     â”‚         enriched_eng.fit(reference_data)  # Or load saved state
     â”‚
     â”œâ”€â”€â–º Receive new data
     â”‚         new_item = get_new_item()
     â”‚
     â”œâ”€â”€â–º Transform features
     â”‚         auction_features = auction_eng.transform(new_auction)
     â”‚         item_features = item_eng.transform(new_item)
     â”‚         enriched_features = enriched_eng.transform(new_enriched)
     â”‚
     â”œâ”€â”€â–º Merge features
     â”‚         merger = DatasetMerger()
     â”‚         final_features = merger.merge(
     â”‚             auction_features,
     â”‚             item_features,
     â”‚             enriched_features
     â”‚         )
     â”‚
     â”œâ”€â”€â–º Make prediction
     â”‚         prediction = model.predict(final_features[model_columns])
     â”‚
     â””â”€â”€â–º Return result
               return {"prediction": prediction}
```

## Class Hierarchy

```
feature_engineering/
â”‚
â”œâ”€â”€ AuctionFeatureEngineer
â”‚   â”œâ”€â”€ __init__()
â”‚   â”œâ”€â”€ fit(df) â†’ self
â”‚   â”œâ”€â”€ transform(df) â†’ df_transformed
â”‚   â”œâ”€â”€ fit_transform(df) â†’ df_transformed
â”‚   â””â”€â”€ get_model_columns() â†’ list
â”‚
â”œâ”€â”€ ItemFeatureEngineer
â”‚   â”œâ”€â”€ __init__(n_components, max_features)
â”‚   â”œâ”€â”€ fit(df) â†’ self
â”‚   â”œâ”€â”€ transform(df) â†’ df_transformed
â”‚   â”œâ”€â”€ fit_transform(df) â†’ df_transformed
â”‚   â”œâ”€â”€ get_model_columns() â†’ list
â”‚   â”œâ”€â”€ save_models(path)        # â˜… For deployment
â”‚   â””â”€â”€ load_models(path)        # â˜… For inference
â”‚
â”œâ”€â”€ ItemEnrichedFeatureEngineer
â”‚   â”œâ”€â”€ __init__(top_brands, top_categories, top_attributes)
â”‚   â”œâ”€â”€ fit(df) â†’ self
â”‚   â”œâ”€â”€ transform(df) â†’ df_transformed
â”‚   â”œâ”€â”€ fit_transform(df) â†’ df_transformed
â”‚   â””â”€â”€ get_model_columns() â†’ list
â”‚
â””â”€â”€ DatasetMerger
    â”œâ”€â”€ __init__()
    â””â”€â”€ merge(df_auction, df_items, df_enriched=None) â†’ df_merged

utils/
â”‚
â””â”€â”€ KaggleDataPipeline
    â”œâ”€â”€ __init__(kaggle_json_path)
    â”œâ”€â”€ download_dataset(dataset_name, download_path)
    â”œâ”€â”€ load_dataset(file_path) â†’ DataFrame
    â”œâ”€â”€ save_dataset(df, file_path, file_format)
    â”œâ”€â”€ upload_dataset(dataset_dir, dataset_slug, ...)
    â””â”€â”€ dataset_exists(dataset_slug) â†’ bool
```

## Data Transformation Flow

```
AUCTION DATA TRANSFORMATION:

Raw Auction Data
    â”œâ”€â”€ starts, ends â†’ auction_length_hours
    â”œâ”€â”€ removal_info â†’ postal_code, postal_code_pd_*
    â”œâ”€â”€ intro â†’ intro_cleaned, intro_length
    â”œâ”€â”€ pickup_time â†’ pickup_day_*, pickup_is_weekend, pickup_time_hour
    â”œâ”€â”€ partner_url â†’ has_partner_url
    â”œâ”€â”€ removal_info â†’ pickup_during_work_hours
    â””â”€â”€ title â†’ is_seller_managed, is_condo_auction, is_storage_unit_auction


ITEM DATA TRANSFORMATION:

Raw Item Data
    â”œâ”€â”€ title, description â†’ TF-IDF â†’ SVD â†’ combined_emb_0..63
    â”œâ”€â”€ current_bid â†’ current_bid_le_10_binary
    â””â”€â”€ current_bid â†’ log_current_bid


ITEM ENRICHED DATA TRANSFORMATION:

Raw Enriched Data
    â”œâ”€â”€ title, description, qualitativeDescription â†’ length features
    â”œâ”€â”€ brand â†’ has_brand, brand_*
    â”œâ”€â”€ brands â†’ has_multiple_brands
    â”œâ”€â”€ categories (JSON) â†’ cat_*
    â”œâ”€â”€ condition â†’ condition_*
    â”œâ”€â”€ working â†’ is_working
    â”œâ”€â”€ singleKeyItem, numItems â†’ item complexity features
    â”œâ”€â”€ attributes (JSON) â†’ attr_*, has_attributes
    â”œâ”€â”€ seriesLine â†’ has_series_line
    â”œâ”€â”€ description â†’ desc_has_luxury, desc_has_vintage, etc.
    â””â”€â”€ multiple fields â†’ data_completeness_score


FINAL MERGE:

  Items (left)
      â”‚
      â”œâ”€â”€ LEFT JOIN Auction ON auction_id
      â”‚       (adds auction features to each item)
      â”‚
      â””â”€â”€ LEFT JOIN Enriched ON item_id
              (adds enriched features to each item)
              
  Result: One row per item with all features
```

## File Organization

```
maxsold/
â”‚
â”œâ”€â”€ ğŸ“ feature_engineering/          # Core transformation logic
â”‚   â”œâ”€â”€ __init__.py                  # Package exports
â”‚   â”œâ”€â”€ auction_features.py          # Auction transformations
â”‚   â”œâ”€â”€ item_features.py             # Item + text embedding transformations
â”‚   â”œâ”€â”€ item_enriched_features.py    # Enriched item transformations
â”‚   â””â”€â”€ dataset_merger.py            # Dataset merging logic
â”‚
â”œâ”€â”€ ğŸ“ utils/                        # Supporting utilities
â”‚   â”œâ”€â”€ __init__.py                  # Package exports
â”‚   â””â”€â”€ kaggle_pipeline.py           # Kaggle API wrapper
â”‚
â”œâ”€â”€ ğŸ“ data/                         # Data storage (gitignored)
â”‚   â”œâ”€â”€ raw/                         # Downloaded from Kaggle
â”‚   â”œâ”€â”€ engineered/                  # Transformed datasets
â”‚   â”œâ”€â”€ final/                       # Merged dataset
â”‚   â””â”€â”€ models/                      # Saved models (TF-IDF, SVD)
â”‚
â”œâ”€â”€ ğŸ“„ run_pipeline.py               # Main orchestration
â”œâ”€â”€ ğŸ“„ test_modules.py               # Testing suite
â”œâ”€â”€ ğŸ“„ quickstart.py                 # Interactive menu
â”‚
â””â”€â”€ ğŸ“š Documentation
    â”œâ”€â”€ README_PIPELINE.md           # Technical documentation
    â”œâ”€â”€ REFACTORING_SUMMARY.md       # What was changed
    â”œâ”€â”€ QUICKSTART.md                # Quick start guide
    â””â”€â”€ ARCHITECTURE.md              # This file
```

## Design Patterns Used

### 1. Fit/Transform Pattern (Scikit-learn style)
```python
# Training
engineer.fit(training_data)           # Learn parameters
df_train = engineer.transform(training_data)

# Inference
df_test = engineer.transform(test_data)  # Use learned parameters
```

### 2. Pipeline Pattern
```python
# Chain transformations
df = load_data()
df = auction_engineer.transform(df)
df = item_engineer.transform(df)
df = enriched_engineer.transform(df)
df = merger.merge(...)
```

### 3. Strategy Pattern
```python
# Different pipelines for different needs
if training:
    engineer.fit_transform(data)
    engineer.save_models()
else:
    engineer.load_models()
    engineer.transform(data)
```

### 4. Facade Pattern
```python
# KaggleDataPipeline wraps complex Kaggle API
kaggle = KaggleDataPipeline()
kaggle.download_dataset(...)  # Simple interface
kaggle.upload_dataset(...)    # Hides complexity
```

## Key Design Decisions

### âœ… Why Fit/Transform?
- Ensures consistency between training and inference
- Prevents data leakage
- Follows ML best practices

### âœ… Why Save Models?
- Text embeddings require fitted TF-IDF vectorizer and SVD
- Loading saves time vs. re-fitting
- Ensures exact same transformations

### âœ… Why Separate Classes?
- Single responsibility principle
- Easy to test individually
- Reusable in different contexts
- Can extend/modify independently

### âœ… Why Kaggle Integration?
- Version control for datasets
- Easy collaboration
- Reproducible experiments
- Backup and sharing

## Performance Characteristics

### Training Phase
- **Auction Features**: Fast (~1-2 sec for 10K rows)
- **Item Features**: Moderate (~30-60 sec for 100K rows)
  - TF-IDF fitting: ~20 sec
  - SVD fitting: ~10 sec
- **Enriched Features**: Fast (~2-5 sec for 100K rows)
- **Merging**: Fast (~1-3 sec)

### Inference Phase
- **Single Item**: < 10 ms
- **Batch (1000 items)**: < 1 sec
- **Large Batch (100K items)**: ~20-30 sec

## Scalability Considerations

### Current Implementation
- In-memory processing with pandas
- Suitable for datasets up to ~1M rows

### For Larger Scale
- Use Dask for distributed processing
- Process in chunks
- Use sparse matrices for embeddings
- Consider database storage

## Extension Points

### Adding New Features
1. Add to appropriate class's `transform()` method
2. Update `get_model_columns()` if needed

### Adding New Dataset
1. Create new FeatureEngineer class
2. Implement fit/transform
3. Add to merger

### Custom Transformations
```python
class CustomFeatureEngineer:
    def fit(self, df):
        # Learn parameters
        return self
    
    def transform(self, df):
        # Apply transformations
        return df_transformed
```

## Best Practices

âœ… Always fit on training data only  
âœ… Save fitted transformers for production  
âœ… Use same Python environment  
âœ… Version control your data (Kaggle)  
âœ… Test with single records before batch  
âœ… Monitor feature distributions in production  
âœ… Document feature engineering decisions  

---

This architecture provides a solid foundation for both batch processing and real-time ML applications!
